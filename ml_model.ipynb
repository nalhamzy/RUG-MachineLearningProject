{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/44/8f37035f0558e597108e5aa7952f7b422a6eb1275b24f7d31027171700d0/opencv_python-4.5.1.48-cp37-cp37m-macosx_10_13_x86_64.whl (40.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 40.3MB 564kB/s ta 0:00:011    55% |█████████████████▊              | 22.4MB 1.2MB/s eta 0:00:15    63% |████████████████████▎           | 25.5MB 1.3MB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /Users/nadir/Library/Python/3.7/lib/python/site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install  opencv-python --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.layers import Input, Dense\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report,log_loss,confusion_matrix\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_classif,SelectKBest\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "WEIGHT_LOC = './saved_model/'\n",
    "IMG_LOC = './img/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions , used to computer the results in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load training images \n",
    "def loadTrainingImages():\n",
    "  tr_images = []\n",
    "  tr_labels = []\n",
    "  val_images = []\n",
    "  val_labels = []\n",
    "\n",
    "\n",
    "  #train_path = '/content/gdrive/MyDrive/Colab Notebooks/ML-Project/archive.zip (Unzipped Files)/chest_xray/train/'\n",
    "  #val_path = '/content/gdrive/MyDrive/Colab Notebooks/ML-Project/archive.zip (Unzipped Files)/chest_xray/val/'\n",
    "\n",
    "  for img in glob.glob(IMG_LOC +\"normal/*.jpeg\"):\n",
    "      s = cv2.imread(img)\n",
    "      #s = cv2.resize(s,(512,512))\n",
    "      tr_images.append(s)\n",
    "      tr_labels.append(0.0)\n",
    "  for img in glob.glob(IMG_LOC+'p/*.jpeg'):\n",
    "      s = cv2.imread(img)\n",
    "      #s = cv2.resize(s,(512,512))\n",
    "      tr_images.append(s)\n",
    "      tr_labels.append(1.0)\n",
    "  return tr_images,tr_labels\n",
    "\n",
    "def plot_loss(history): \n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()\n",
    "def plot_accuracy(history) :\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Model Accuracy')\n",
    "  plt.ylabel('acc')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#plot pca \n",
    "def plotPCA(x,nocomponents):\n",
    "    fig= plt.figure(figsize=(7,7))\n",
    "    pca = PCA(n_components=nocomponents)\n",
    "    x_flatten = x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3)\n",
    "\n",
    "    pca.fit(x_flatten)\n",
    "    cum_var_explained = []\n",
    "    for i in range(len(pca.explained_variance_ratio_)):\n",
    "        cum_var_explained.append(sum(pca.explained_variance_ratio_[:i]))\n",
    "\n",
    "    plt.plot(list(range(0,len(cum_var_explained))),\n",
    "                cum_var_explained, color=\"darkblue\")\n",
    "    idx_exp_95var = len(cum_var_explained) - 1\n",
    "    idx_exp_90var = len(cum_var_explained) - 1\n",
    "    idx = np.where(np.array(cum_var_explained) >= 0.95)\n",
    "    print(idx)\n",
    "    if idx[0].shape[0] > 0:\n",
    "        idx_exp_95var = idx[0][0]\n",
    "    idx = np.where(np.array(cum_var_explained) >= 0.99)\n",
    "    print(idx)\n",
    "\n",
    "    if idx[0].shape[0] > 0:\n",
    "        idx_exp_99var = idx[0][0]\n",
    "\n",
    "    #plt.plot([0,len(cum_var_explained)],[0.95,0.95],'--',color='darkblue')\n",
    "    #plt.plot([idx_exp_95var,idx_exp_95var],[0,1],'--', color='darkblue')\n",
    "    plt.plot(idx_exp_95var,0.95,'ro', color='red')\n",
    "    plt.plot(idx_exp_99var,0.99,'ro', color='red')\n",
    "\n",
    "    plt.xlabel('No. of components', fontsize=12)\n",
    "    plt.ylabel('Percent Variance Explained', fontsize=12)\n",
    "    plt.text(250, 0.92, '95%', fontsize=11,\n",
    "          verticalalignment='center')\n",
    "    plt.text(1250, 0.94, '99%',fontsize=11,\n",
    "          verticalalignment='center')\n",
    "\n",
    "    plt.plot()\n",
    "    return pca \n",
    "def fitLogisticRegression(x,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    x_flatten = x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3)\n",
    "\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0).fit(x_flatten, y)\n",
    "    return model\n",
    "def fitANOVA(x,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    x_flatten = np.array(x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3))\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    fs.fit(x_flatten,y)\n",
    "    idx_sorted      = np.argsort(fs.scores_)\n",
    "    idx_sorted_desc = np.argsort(fs.scores_)[::-1]\n",
    "    return idx_sorted_desc\n",
    "\n",
    "def make_model_best(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    #x = data_augmentation(inputs)\n",
    "    x = layers.Dense(32)(inputs)\n",
    "\n",
    "    for size in [32,64]:\n",
    "    # Entry block\n",
    "      x = layers.Conv2D(size, kernel_size=3,strides=2,  padding=\"same\")(x)\n",
    "      x = layers.BatchNormalization()(x)\n",
    "      x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "def load_best_model():\n",
    "    image_size =(128, 128,3)\n",
    "\n",
    "    model = make_model_best(image_size,1)\n",
    "    model = keras.models.load_model(WEIGHT_LOC)\n",
    "\n",
    "    return model\n",
    "def normalize(x):\n",
    "    return np.array(x/255)\n",
    "\n",
    "\n",
    "def create_ResNet50_model(input_tensor = Input(shape=(128, 128, 3)),\n",
    "                          output_units = 1,optimizer='adam', weights='imagenet'):\n",
    "  base_model = ResNet50(input_tensor=input_tensor, weights=weights)\n",
    "  base_model.layers.pop()\n",
    "  base_model.outputs = [base_model.layers[-1].output]\n",
    "  #base_model.layers[-1].outbound_nodes = []\n",
    " # output = Dense(64, activation='relu')(base_model.output)\n",
    "  predictions = Dense(output_units, activation='sigmoid')(base_model.output)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "  #for layer in base_model.layers:\n",
    "    #layer.trainable = False\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data & fitting 2-covolutional neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65537     \n",
      "=================================================================\n",
      "Total params: 93,793\n",
      "Trainable params: 93,601\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x,y = loadTrainingImages()\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x = normalize(x)\n",
    "\n",
    "model = make_model_best((128, 128,3),1)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    epochs=22#,\n",
    "    \n",
    "    #callbacks=[es_callback]\n",
    ")\n",
    "#print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65537     \n",
      "=================================================================\n",
      "Total params: 93,793\n",
      "Trainable params: 93,601\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_best_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
