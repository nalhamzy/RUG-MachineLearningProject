{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/44/8f37035f0558e597108e5aa7952f7b422a6eb1275b24f7d31027171700d0/opencv_python-4.5.1.48-cp37-cp37m-macosx_10_13_x86_64.whl (40.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 40.3MB 564kB/s ta 0:00:011    55% |█████████████████▊              | 22.4MB 1.2MB/s eta 0:00:15    63% |████████████████████▎           | 25.5MB 1.3MB/s eta 0:00:12\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /Users/nadir/Library/Python/3.7/lib/python/site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install  opencv-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.layers import Input, Dense\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report,log_loss,confusion_matrix\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_classif,SelectKBest\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "WEIGHT_LOC = ''\n",
    "IMG_LOC = './img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load training images \n",
    "def loadTrainingImages():\n",
    "  tr_images = []\n",
    "  tr_labels = []\n",
    "  val_images = []\n",
    "  val_labels = []\n",
    "\n",
    "\n",
    "  #train_path = '/content/gdrive/MyDrive/Colab Notebooks/ML-Project/archive.zip (Unzipped Files)/chest_xray/train/'\n",
    "  #val_path = '/content/gdrive/MyDrive/Colab Notebooks/ML-Project/archive.zip (Unzipped Files)/chest_xray/val/'\n",
    "\n",
    "  for img in glob.glob(IMG_LOC +\"normal/*.jpeg\"):\n",
    "      s = cv2.imread(img)\n",
    "      #s = cv2.resize(s,(512,512))\n",
    "      tr_images.append(s)\n",
    "      tr_labels.append(0.0)\n",
    "  for img in glob.glob(IMG_LOC+'p/*.jpeg'):\n",
    "      s = cv2.imread(img)\n",
    "      #s = cv2.resize(s,(512,512))\n",
    "      tr_images.append(s)\n",
    "      tr_labels.append(1.0)\n",
    "  return tr_images,tr_labels\n",
    "\n",
    "def plot_loss(history): \n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()\n",
    "def plot_accuracy(history) :\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Model Accuracy')\n",
    "  plt.ylabel('acc')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#plot pca \n",
    "def plotPCA(x,nocomponents):\n",
    "    fig= plt.figure(figsize=(7,7))\n",
    "    pca = PCA(n_components=nocomponents)\n",
    "    x_flatten = x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3)\n",
    "\n",
    "    pca.fit(x_flatten)\n",
    "    cum_var_explained = []\n",
    "    for i in range(len(pca.explained_variance_ratio_)):\n",
    "        cum_var_explained.append(sum(pca.explained_variance_ratio_[:i]))\n",
    "\n",
    "    plt.plot(list(range(0,len(cum_var_explained))),\n",
    "                cum_var_explained, color=\"darkblue\")\n",
    "    idx_exp_95var = len(cum_var_explained) - 1\n",
    "    idx_exp_90var = len(cum_var_explained) - 1\n",
    "    idx = np.where(np.array(cum_var_explained) >= 0.95)\n",
    "    print(idx)\n",
    "    if idx[0].shape[0] > 0:\n",
    "        idx_exp_95var = idx[0][0]\n",
    "    idx = np.where(np.array(cum_var_explained) >= 0.99)\n",
    "    print(idx)\n",
    "\n",
    "    if idx[0].shape[0] > 0:\n",
    "        idx_exp_99var = idx[0][0]\n",
    "\n",
    "    #plt.plot([0,len(cum_var_explained)],[0.95,0.95],'--',color='darkblue')\n",
    "    #plt.plot([idx_exp_95var,idx_exp_95var],[0,1],'--', color='darkblue')\n",
    "    plt.plot(idx_exp_95var,0.95,'ro', color='red')\n",
    "    plt.plot(idx_exp_99var,0.99,'ro', color='red')\n",
    "\n",
    "    plt.xlabel('No. of components', fontsize=12)\n",
    "    plt.ylabel('Percent Variance Explained', fontsize=12)\n",
    "    plt.text(250, 0.92, '95%', fontsize=11,\n",
    "          verticalalignment='center')\n",
    "    plt.text(1250, 0.94, '99%',fontsize=11,\n",
    "          verticalalignment='center')\n",
    "\n",
    "    plt.plot()\n",
    "    return pca \n",
    "def fitLogisticRegression(x,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    x_flatten = x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3)\n",
    "\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0).fit(x_flatten, y)\n",
    "    return model\n",
    "def fitANOVA(x,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    x_flatten = np.array(x.reshape(x.shape[0],x.shape[1]*x.shape[2]*3))\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    fs.fit(x_flatten,y)\n",
    "    idx_sorted      = np.argsort(fs.scores_)\n",
    "    idx_sorted_desc = np.argsort(fs.scores_)[::-1]\n",
    "    return idx_sorted_desc\n",
    "\n",
    "def make_model_best(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    #x = data_augmentation(inputs)\n",
    "    x = layers.Dense(32)(inputs)\n",
    "\n",
    "    for size in [32,64]:\n",
    "    # Entry block\n",
    "      x = layers.Conv2D(size, kernel_size=3,strides=2,  padding=\"same\")(x)\n",
    "      x = layers.BatchNormalization()(x)\n",
    "      x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "def load_best_model():\n",
    "    image_size =(128, 128,3)\n",
    "\n",
    "    model = make_model_best(image_size,1)\n",
    "    model = keras.models.load_model(WEIGHT_LOC)\n",
    "\n",
    "    return model\n",
    "def normalize(x):\n",
    "    return np.array(x/255)\n",
    "\n",
    "\n",
    "def create_ResNet50_model(input_tensor = Input(shape=(128, 128, 3)),\n",
    "                          output_units = 1,optimizer='adam', weights='imagenet'):\n",
    "  base_model = ResNet50(input_tensor=input_tensor, weights=weights)\n",
    "  base_model.layers.pop()\n",
    "  base_model.outputs = [base_model.layers[-1].output]\n",
    "  #base_model.layers[-1].outbound_nodes = []\n",
    " # output = Dense(64, activation='relu')(base_model.output)\n",
    "  predictions = Dense(output_units, activation='sigmoid')(base_model.output)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "  #for layer in base_model.layers:\n",
    "    #layer.trainable = False\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5217, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#x,y = loadTrainingImages()\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x = normalize(x)\n",
    "print(x.shape)\n",
    "x = x/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "164/164 [==============================] - 32s 197ms/step - loss: 0.2428 - accuracy: 0.8999\n",
      "Epoch 2/22\n",
      "164/164 [==============================] - 33s 200ms/step - loss: 0.1175 - accuracy: 0.9550\n",
      "Epoch 3/22\n",
      "164/164 [==============================] - 40s 244ms/step - loss: 0.1012 - accuracy: 0.9634\n",
      "Epoch 4/22\n",
      "164/164 [==============================] - 38s 229ms/step - loss: 0.0832 - accuracy: 0.9716\n",
      "Epoch 5/22\n",
      "164/164 [==============================] - 39s 238ms/step - loss: 0.0702 - accuracy: 0.9739\n",
      "Epoch 6/22\n",
      "164/164 [==============================] - 37s 228ms/step - loss: 0.0619 - accuracy: 0.9768\n",
      "Epoch 7/22\n",
      "164/164 [==============================] - 36s 217ms/step - loss: 0.0537 - accuracy: 0.9808\n",
      "Epoch 8/22\n",
      "164/164 [==============================] - 35s 216ms/step - loss: 0.0447 - accuracy: 0.9833\n",
      "Epoch 9/22\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 0.0367 - accuracy: 0.9881\n",
      "Epoch 10/22\n",
      "164/164 [==============================] - 35s 216ms/step - loss: 0.0343 - accuracy: 0.9883\n",
      "Epoch 11/22\n",
      "164/164 [==============================] - 39s 239ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "Epoch 12/22\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.0210 - accuracy: 0.9941\n",
      "Epoch 13/22\n",
      "164/164 [==============================] - 36s 220ms/step - loss: 0.0159 - accuracy: 0.9971\n",
      "Epoch 14/22\n",
      "164/164 [==============================] - 35s 214ms/step - loss: 0.0147 - accuracy: 0.9969\n",
      "Epoch 15/22\n",
      "164/164 [==============================] - 38s 233ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 16/22\n",
      "164/164 [==============================] - 33s 202ms/step - loss: 0.0092 - accuracy: 0.9994\n",
      "Epoch 17/22\n",
      "164/164 [==============================] - 35s 211ms/step - loss: 0.0073 - accuracy: 0.9996\n",
      "Epoch 18/22\n",
      "164/164 [==============================] - 35s 216ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 19/22\n",
      "164/164 [==============================] - 37s 224ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 20/22\n",
      "164/164 [==============================] - 34s 210ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 21/22\n",
      "164/164 [==============================] - 34s 209ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 22/22\n",
      "164/164 [==============================] - 35s 213ms/step - loss: 0.0033 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = make_model_best((128, 128,3),1)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    epochs=22#,\n",
    "    \n",
    "    #callbacks=[es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
